{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9157f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### \n",
    "# This cell is meant to install packages if some are missing\n",
    "#######\n",
    "\n",
    "# !pip install tqdm scipy\n",
    "# !pip install matplotlib\n",
    "# !pip install opencv-contrib-python\n",
    "# !pip install numpy\n",
    "# !pip install --upgrade tdmclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def0ebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from kalmanfilter import KalmanFilter\n",
    "import cv2   # a clean up\n",
    "import local_nav as ln\n",
    "import math \n",
    "from Motion_control import MotionControl\n",
    "from djikstra import djikstra_algo,create_plot\n",
    "from calibration import data\n",
    "\n",
    "### Connect the thymio(the speed set to 0 is here in case of an error during calibration or during the code)\n",
    "from tdmclient import ClientAsync, aw\n",
    "client = ClientAsync()\n",
    "node = aw(client.wait_for_node())\n",
    "aw(node.lock())\n",
    "\n",
    "\n",
    "#we initialize the calibration calss aswell as some values that are needed throughout the entire code\n",
    "Ts = 0.1\n",
    "SPEED_L = 101\n",
    "SPEED_R = 98\n",
    "GND_THRESHOLD = 400\n",
    "\n",
    "mc = MotionControl(node, client, Ts, SPEED_R, SPEED_L)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03ceee3c",
   "metadata": {},
   "source": [
    "# Calibration\n",
    "\n",
    "In this section, we will run multiple functions, in order to calibrate our thymio to the current environement. This gives us more flexibility, and makes it easier to use different thymio in different environment.\n",
    "\n",
    "### Calibration of the thymio \n",
    "\n",
    "In this first step, we will use the following image to calibrate the speed, its conversion ratio from the thymio's sensor to mm/s, and its variance for the Kalman filter.\n",
    "\n",
    "<img src=\"Pictures/Picture1.jpg\" width=\"900\"/>\n",
    "\n",
    "In this next function, we will ask the thymio to move forward, at a known speed. As soon as its ground sensor detect it is on the black line, it will start a timer. When it exits the line, the timer will stop, the thymio will stop aswell, and all the desired values will be computed. In this function, the line length is know and we need to be carefully align the thymio as to make it follow the line. From this test, we can also adjust the speed on the left and right wheel to make it go as straight as possible and adjust the transition threshold if the light's intensity in the current room requires it.\n",
    "\n",
    "The following cell needs to be executed in order to initialize the calibration class, and start the calibration process. It will then give back the values in the form of a print, and give two functions we can replace the ones mentionned earlier. We have made it this way for debugging purposes. When changing code in other files that are imported, we need to restart the jupyter kernel and rerun all the cells to initialize everything. But we already know the values of the previous calibration, and if we are in the same room, with the same map and the same thymio, we know these value shouldn't change by a large margin. The two new functions will initialize everything, paste the values found earlier, and won't run the calibration process again. And if we need to change it back, the two  new functions, for the calibration process, would again be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_data = data(Ts, SPEED_L, SPEED_R, GND_THRESHOLD, client, node, 0.329506587331065, 6.793596512574189)\n",
    "cal_data.calibration_mm(mc)\n",
    "mc.speed_conversion = cal_data.speed_conversion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95e5ebfe",
   "metadata": {},
   "source": [
    "### Calibration of the camera\n",
    "In this next cell, we will retrieve the the grid from the camera, and do all the conversions requiered for the rest of the project. \n",
    "\n",
    "We initialize the vision class here, with a calibration function, because of the light's density in our current room. We often needed to adjust the threshold for multiple detection process in this class. We could've automated the process, but have decided against it, as it never was a time-consuming task. We would usually run the cell bellow with the DEBUG defined as true, check the number of obstacles, and from this, we immediatly knew what to do with our threshold value, and change it once, or twice at the very maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a5f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# be careful that if you have not called the previous cell, this will automatically set the missing values\n",
    "nbAruco = 2\n",
    "threshold = 100\n",
    "calibrate = False\n",
    "vision, Q_cam, R_cam= cal_data.cam_calibration(calibrate, nbAruco, threshold)\n",
    "\n",
    "HALF_CELL_WIDTH = vision.cell_width/2\n",
    "if(DEBUG == True):\n",
    "    print(\"Number of obstacles = \", np.count_nonzero(vision.grid))\n",
    "    print(vision.grid)\n",
    "    lines = vision.show()\n",
    "    plt.figure\n",
    "    plt.title('Lines')\n",
    "    plt.imshow(cv2.cvtColor(lines.astype('uint8'), cv2.COLOR_BGR2RGB))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7255bc1e",
   "metadata": {},
   "source": [
    "### Kalman's filter\n",
    "\n",
    "The filter we have chosen to use is the kalman's filter. With the use of the camera, and the thymio's speed sensor, we have two different sensor with which we can use the Kalman's filter. It's implementation is traditionnal. Again, we have gone for the usage of a class, as it makes it easier to use, and track the values. \n",
    "The one section where we had room to play with, were the values of the covariance of process noise's matrices Q, and the values of the covariance of the measurement's noise R.\n",
    "\n",
    " $R = \\begin{bmatrix} r_p & 0\\\\ 0 & r_\\nu \\end{bmatrix}$\n",
    " $Q = \\begin{bmatrix} q_p & 0\\\\ 0 & q_\\nu \\end{bmatrix}$\n",
    "\n",
    "The values have been computed using the same method as in the exercise of week 8. The $r_\\nu$ and $q_\\nu$ have been computed inside the calibration process. For $q_p$ and $r_p$, it was a little bit more difficult. An issue we had, was the deformation of the image due to the lens, and the position of the camera. \n",
    "\n",
    "<img src=\"Pictures/Camera_pos.jpg\" />\n",
    "\n",
    "When placing the camera, we always placed it perfectly in the middle of the grid along its x axis, but because of our setup, we could never place it in the middle of its width along the y axis aswell. It was always on the side. This induced an error on the y position of the thymio. We have fixed it by placing a y_offset in the vision class. With this offset, we managed to correct the position in y from the camera's perspective, but it wasn't perfect either. We still had an error of approximatively Â±5mm. Based on the exercise of week 8 again, we decided to set $r_p$ = 0.01 But while testing this, we also managed to see the variance on the position from the camera's perspective. We found from this that the standard deviation was ~0.5mm, so we have set $q_p$ =  0.25mm\n",
    "\n",
    "\n",
    "For this filter, we've inspired ourselves from the courses and the youtuber \"L42\" and his [github](https://github.com/L42Project/Tutoriels/tree/master/Divers/tutoriel36), to properly understand the filter. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dac1c33d",
   "metadata": {},
   "source": [
    "### Run code\n",
    "\n",
    "Now that everything has been explained, we simply need to run the cell bellow to execute thymio's task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec82cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision.update_coordinates()\n",
    "if(DEBUG == True):\n",
    "    print(\"thymio real pos : \", vision.thymio_real_pos)\n",
    "    print(\"thymio pos in grid : \", vision.thymio_position)\n",
    "    print(\"goal pos : \", vision.goal_position)\n",
    "    print(\"thymio angle = :\", vision.thymio_orientation)\n",
    "vision.grid[vision.thymio_position[1]][vision.thymio_position[0]] = 0\n",
    "vision.grid[vision.goal_position[1]][vision.goal_position[0]] = 0\n",
    "shortest_path = djikstra_algo(vision.grid.T, vision.thymio_position, vision.goal_position)\n",
    "if(DEBUG == True):\n",
    "    print(shortest_path)\n",
    "\n",
    "KF = KalmanFilter(Ts, vision.thymio_real_pos, cal_data.speed_conversion, Q_cam, R_cam)  # we initialize the filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2587ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mc.step_duration = HALF_CELL_WIDTH*2 / (mc.SPEED_AVG * mc.speed_conversion)\n",
    "mc.turn_duration = 98 / (mc.SPEED_AVG * mc.speed_conversion)\n",
    "restart = True\n",
    "\n",
    "jump_x, jump_y = 0,0\n",
    "MARGIN = 40\n",
    "change_dir = False\n",
    "while (restart == True):\n",
    "    jump = False\n",
    "    index = 0\n",
    "    restart = False\n",
    "    vision.update_coordinates()\n",
    "    if(DEBUG == True):\n",
    "        print(\"thymio real pos : \", vision.thymio_real_pos)\n",
    "        print(\"thymio pos in grid : \", vision.thymio_position)\n",
    "        print(\"goal pos : \", vision.goal_position)\n",
    "        print(\"thymio angle = :\", vision.thymio_orientation)\n",
    "    vision.grid[vision.thymio_position[1]][vision.thymio_position[0]] = 0\n",
    "    vision.grid[vision.goal_position[1]][vision.goal_position[0]] = 0\n",
    "    shortest_path = djikstra_algo(vision.grid.T, vision.thymio_position, vision.goal_position)\n",
    "    if(DEBUG == True):\n",
    "        print(shortest_path)\n",
    "    KF = KalmanFilter(Ts, vision.thymio_real_pos, cal_data.speed_conversion, Q_cam, R_cam)\n",
    "    mc.orientation = mc.correct_orientation(vision.thymio_orientation)\n",
    "    x = vision.thymio_position[0]\n",
    "    y = vision.thymio_position[1]\n",
    "    speed = np.array([SPEED_L, SPEED_R])\n",
    "    turn_speed = np.array([0, 0])\n",
    "    for dx,dy in np.transpose(shortest_path):\n",
    "        if jump:\n",
    "            x = dx      #actualize the coordinates of the robot\n",
    "            y = dy      #actualize the coordinates of the robot\n",
    "            index += 1\n",
    "            if jump_x == dx and jump_y == dy:\n",
    "                jump = False\n",
    "            continue  \n",
    "        vision.update_coordinates()\n",
    "        if(vision.goal_position != vision.goal_previous) & (change_dir != True):\n",
    "            change_dir = True\n",
    "            restart = True\n",
    "            break\n",
    "        turn = mc.get_turn(dx-x,dy-y,mc.orientation)\n",
    "        mc.orientation = (mc.orientation + turn)%4\n",
    "        for i in range(abs(turn)):\n",
    "            mc.robot_turn(np.sign(turn))\n",
    "        mc.adjust_angle(vision)\n",
    "        if (((dx-x)!=0) | ((dy-y)!=0)):\n",
    "            local = ln.obstacle_detect(node)\n",
    "            if local:\n",
    "                if(DEBUG == True):\n",
    "                    print(\"obstacle\",len(shortest_path[1]))\n",
    "                jump,jump_x,jump_y = ln.obstacle_avoid(vision, mc, x, y, shortest_path, index, node, client)\n",
    "            else:   \n",
    "                if (((dx-x)!=0) | ((dy-y)!=0)):\n",
    "                    step_done = False\n",
    "                    start_move = time.time()\n",
    "                    mc.motors(speed[0], speed[1])\n",
    "                    temp = 0\n",
    "                    next_target_x = dx *HALF_CELL_WIDTH*2 + HALF_CELL_WIDTH\n",
    "                    next_target_y = (vision.rows - 1 - dy) *HALF_CELL_WIDTH*2 + HALF_CELL_WIDTH\n",
    "                    \n",
    "                    while (step_done != True):  \n",
    "                        vision.update_coordinates()\n",
    "                        kalman_pos= KF.filter(vision.thymio, vision.thymio_real_pos, speed, vision.thymio_orientation)\n",
    "                        if(DEBUG == True):\n",
    "                            print(\"estimated position \", kalman_pos)\n",
    "                            print(\"position from camera \", vision.thymio_real_pos)\n",
    "                        delta_x, delta_y= mc.kalman_adjust(next_target_x, next_target_y, kalman_pos, vision.thymio_orientation)\n",
    "                        current = time.time()\n",
    "                        temp = current - start_move\n",
    "                        if((np.abs(delta_x) < MARGIN) & (np.abs(delta_y) < MARGIN)):\n",
    "                            step_done = True\n",
    "                            mc.motors(0, 0) \n",
    "                        elif(temp > mc.step_duration):\n",
    "                            step_done = True  \n",
    "                            mc.motors(0, 0)\n",
    "                \n",
    "                    mc.adjust_angle(vision)\n",
    "\n",
    "        x = dx      #actualize the coordinates of the robot\n",
    "        y = dy      #actualize the coordinates of the robot\n",
    "        index += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ad5b923",
   "metadata": {},
   "source": [
    "### Kalman_adjust\n",
    "\n",
    "With the kalman filter, we get an estimated position of our thymio, from our multiple sensor. But we still need to use these informations. Because of our environement and path finding choices, we have decided to run the Kalman_adjust per cell. This means that we will run the correction *per steps*. We take the center of our thymio from the kalman's estimated position, and take the difference with the center of the next targeted cell. The goal is for the thymio to face the center of this cell. This is what Kalman_adjust do. It computes the angle required to reach the center of the next targeted cell, compares it with the actual thymio's orientation, and runs a proportionnal controller to fix the error. We found two approaches: in both case, we increase the speed of one wheel, while we decrease the speed of the other. This will lead to a rotation of the thymio. Then we could either decide to let this different in speed be, and expect kalman to correct the speed at every sampling time, or, the second approach, the one we went with, set this difference in speed, and let it run for a little time, then reset the speed back to normal. We have decided to set the duration to two sampling time, to be sure it would be long enough for it to affect the locomotion. The first option has also been tested, but resulted in a lot of oscillation from the thymio.\n",
    "\n",
    "The gain was set experimentally. We know that the $k_p * \\omega * t$  ($\\omega$ being the angular velocity) shouldn't exceed the difference in angle from the desired orientation and the actual one. We could've increased the gain up to this limit but found the value of 2.5 was good enough, without being too agressive.\n",
    "Finally, we have also made the choice of ignoring a difference in angle bellow our threshold of 7Â°, because of this imperfection of our setup, and the camera's deformation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d88e54a",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "This project being made of random groups, and over a very short time, forced us to cooperate and communicate properly. We managed to work all together, and help each other face problem we all faced. The task was certainly not always easy, but having this cooperation inside the group was a key aspect of the work we have done.\n",
    "\n",
    "We've also learned, with a practical point of view, how path finding, local navigation, image processing and the filtering actually works\n",
    "\n",
    "We have set a defined goal for this project and feel we have managed to succeed. Surely, we could've made some aspect of our project more raffined, ellaborate, and/or versatile, but given the time available for this project, shared with other project with other group, we are happy with the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b07f2eb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ff010c4fb58d66583690da57b105aade205a845f835d32c4ee88b21f1478465"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
